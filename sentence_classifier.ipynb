{
 "metadata": {
  "name": "",
  "signature": "sha256:eaf2b80df8a7fa951f975dbe4da69f89c2c58a81152fbadac16dd37477854f81"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Sentence Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run db_link.ipynb\n",
      "import nltk\n",
      "import numpy as np\n",
      "import sys\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer         \n",
      "from nltk.stem import WordNetLemmatizer \n",
      "from sklearn.svm import LinearSVC\n",
      "\n",
      "class LemmaTokenizer(object):\n",
      "    def __init__(self):\n",
      "        self.wnl = WordNetLemmatizer()\n",
      "    def __call__(self, doc):\n",
      "        return [self.wnl.lemmatize(t) for t in nltk.word_tokenize(doc)]\n",
      "\n",
      "corpus = []\n",
      "tags = []\n",
      "for s in Tag_Sent.query.find().all():\n",
      "    if s.tag == 'n':\n",
      "        corpus.append(s.trans_sentence)\n",
      "        tags.append(s.tag)\n",
      "    if s.tag == 'i' or s.tag == 't':\n",
      "        corpus.append(s.trans_sentence)\n",
      "        tags.append('i')\n",
      "    if s.tag =='r':\n",
      "        corpus.append(s.trans_sentence)\n",
      "        tags.append(s.tag)\n",
      "\n",
      "vectorizer = CountVectorizer(tokenizer = LemmaTokenizer(), ngram_range =(1,3))\n",
      "vectors = vectorizer.fit_transform(corpus)\n",
      "X = vectors\n",
      "y = np.array(tags)\n",
      "yeah = LinearSVC().fit(X, y)\n",
      "\n",
      "def is_relevant(sentence):\n",
      "    vect = vectorizer.transform([sentence])   \n",
      "    prediction = yeah.predict(vect)\n",
      "    certainty = yeah.decision_function(vect)\n",
      "    return prediction\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DB correctly created/syncronized\n"
       ]
      }
     ],
     "prompt_number": 23
    }
   ],
   "metadata": {}
  }
 ]
}